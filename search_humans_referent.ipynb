{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c6c906-ee5a-40e3-81df-974cccb04b68",
   "metadata": {},
   "source": [
    "# Qu'est-ce qu'il y a dans ce notebook ?\n",
    "\n",
    "Fonctions permettant de calculer et créer un dictionnaire de similarité entre chaque occurence unique de mots  \n",
    "Fonctions permettant d'extraire, pour chaque occurence unique, le mot le plus similaire et de récupérer son nombre d'occurence  \n",
    "Fonctions permettant de recréer un dictionnaire d'occurence pour faciliter l'extraction en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "facc0792-8256-4ce8-ac8c-1b619731d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode = True\n",
    "serialized_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34e232c8-8167-482b-b3f4-51ad906964ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from ipynb.fs.defs.fonctions_preprocess import open_file\n",
    "from ipynb.fs.defs.fonctions_preprocess import serialisation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e797e0-58a6-4819-96fc-147afd670164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger('simple_example')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5c8c8-fb57-495e-b9bd-09689a28c9cc",
   "metadata": {},
   "source": [
    "## Extraction et mise en forme du corpus\n",
    "\n",
    "On extrait le corpus à partir du fichier souhaité (selon fichier en partie sérialisé ou non)  \n",
    "Mise en format du fichier : nécessité de passer d'une liste de mot à une string pour que le module SpaCy fonctionne  \n",
    "Sérialisation de l'objet string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c3d2c-9015-454e-b4e7-fc64f33042c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    with open(file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233eaa0-5362-4aab-acff-ed10d6184c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f15ea64-e6aa-4215-9696-19140ddee2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_string from json file\n",
      "corpus extracted\n"
     ]
    }
   ],
   "source": [
    "if serialized_data == False:\n",
    "    print(\"extracting whole data from noun corpus\")\n",
    "    data = open_file(\"nouns.json\")\n",
    "    print(len(data))\n",
    "else:\n",
    "    print(\"Extracting data_string from json file\")\n",
    "    corpus = open_file(\"corpus_string.json\")\n",
    "    print(\"corpus extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e85e92a-ba81-4f5f-9e9d-a045fac8e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376266\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dba47d2c-b7e5-46bb-8c1a-18f9064d1fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n",
      "soumettrait HBO CNES jettés d\"horizons supercitoyens Éthiques cratère inconnu.e.s d'\"association d'\"organisation criminels\"qui chosifiant profiteuse plasmas mx soudage réenforcement musulmans+maghrébins Solides ré-enforcement jeunesse/ cij sans-domiciles débriefings Qqun viendrai devraiot palnète de.l mise.en les.mineurs freqentation de.quartiers des.places.de.prison avec.application des.peines iere kosovards refroupements https://jugementmajoritaire.net multi-cumulars loraine délégue primo-délinquant êlections applicaton MATURATION TOTALITAIRE disponibilité.le nlveau M.LePen 20éme renouvelees tonalite relativite ¨Prefectures Psycho XiX superfétatoires grand[s nationa[ux branchement rapporf hûmain psychogénéalogie bercée excrémentales naturalité tribution tributions Déséquilibré mono-diète ré-actualisation des-mots-cratie nstrative nstrations agencements non-républicaines conjugue subjectives texte]. sympatoche singulariste discutere secouant réagencement plissent co-élire coélitaires contre-utopies étrangéisation Eschatologie métonymie étymologies etumon etumologia trébuchement poétiques arpentage arpent mesureur interpréteur contribuant Littéralement mal-à-droite littéralité constipations mé re-dessiné re-combinaison ré-agencement ellipses sanskrit indénombrables gentes goût]. nursing apocope Inadaptés esthétiquement interprétativement publireportage Newspeak enformation Manu636363 plexe syndicus indissociablement dyscompréhensions excrémental respectus Métaphoriquement re-garder disqualificatrice wikiwiki auto-aliénation inertique fastidieux semblante oursons 22h37 bisournours ordinarité champ94 Characters Old' Abominable shadocks schroumpf fugacité félin auto-routier dissociabilité senatus senex collapsologue contre-Greta fustigées élé SUBORINATION RANDOMISE pondeuse Lucas Eurodéputées gentillettes décretant arès mieuxn porximité situatition zolymer78 Sous-titrage REPLAY souriante chgose publiés d'2coute hyperpresidentialisation efficae luie Contournement\n"
     ]
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    test = corpus[1374268:1376261]\n",
    "    print(len(test))\n",
    "    \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d26b9-de6d-4be4-9930-ad52681ab0b3",
   "metadata": {},
   "source": [
    "#### Extraction des noms du tuple et création de la string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725743ff-4645-4290-8c8e-38f3e14788e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_into_string(tuple_list):\n",
    "\n",
    "    extract = []\n",
    "    extract_s = \"\"\n",
    "\n",
    "    #Permet d'enlever les doublons\n",
    "    for tup in tuple_list:\n",
    "        if tup[0] not in extract:\n",
    "            extract.append(tup[0])\n",
    "            \n",
    "    print(\"Taille des occurences uniques : \", len(extract))\n",
    "    logging.info(\"Taille des occurences uniques\")\n",
    "        \n",
    "    for word in extract:\n",
    "        extract_s += word\n",
    "        extract_s += \" \"\n",
    "        \n",
    "    return extract_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7088c7-9932-4c17-9f86-2a8909be21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if serialized_data == False:\n",
    "    corpus = list_into_string(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec1a40-de9c-4613-a1a9-a98652d9b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if serialized_data == False:\n",
    "    serialisation_data (corpus, \"corpus_string.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef7acc-0e12-47a1-9cd0-44c594df3c38",
   "metadata": {},
   "source": [
    "## Calcul de similarités via le module SpaCy\n",
    "\n",
    "Chargement du module avec les vecteurs pré-entrainés `fr_core_news_md`  \n",
    "Chargement du corpus dans deux documents pour s'assurer que tous les tokens seront lus ensemble  \n",
    "Fonctions permettant le calcul de similarité et construction d'un dictionnaire de similarité  \n",
    "Sérialisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93f8fd-f385-405f-8f7e-8a71a4c7126b",
   "metadata": {},
   "source": [
    "#### Chargement du module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dd625e2-acf4-4be6-90b2-d2c53dae1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c85e1c7c-5692-4a91-b7eb-eb2a71df8d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode : corpus test\n"
     ]
    }
   ],
   "source": [
    "nlp.max_length = 1500000\n",
    "\n",
    "if debug_mode:\n",
    "    print(\"debug mode : corpus test\")\n",
    "    doc1 = nlp(test)\n",
    "    doc2 = nlp(test)\n",
    "else:\n",
    "    print(\"dealing with whole corpus\")\n",
    "    doc1 = nlp(corpus, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "    doc2 = nlp(corpus, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2982765-32e9-4ef4-b259-60b62e7562c9",
   "metadata": {},
   "source": [
    "#### Fonctions permettant le calcul de similarité\n",
    "\n",
    "`calculate_similarity` calcule la similarité entre deux mots  \n",
    "`construction_list_similarity` construit une liste de similarité constituée de tuples avec deux mots et leur similarité  \n",
    "`extract_unique_referent` permet, à partir de la liste de similarité, de construire un dictionnaire avec, pour chaque occurence, ses similarités les plus fortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be1b941-eac2-4ee5-afc5-34c249eebd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity (token1, token2):\n",
    "    \"\"\"Calculate Similarity between two tokens using SpaCy pre-trained model\n",
    "    -> Two tokens\n",
    "    <- similarity score between these two tokens\"\"\"\n",
    "\n",
    "    similarity = token1.similarity(token2)\n",
    "    \n",
    "    if similarity >= 0.5 and similarity != 1 : return (token1, token2, similarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ccc1a5-37cd-4833-87df-8952578f4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construction_liste_similarity(doc1, doc2):\n",
    "    \"\"\"Builds list of similarities. One element of the list is built so : (token1, token2, similarity)\n",
    "    -> doc1 : list of words\n",
    "    -> doc2 : other list of words\n",
    "    <- list of tuples made of two words and their similarities\n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range (len(doc1)):\n",
    "        if doc1[i].has_vector != False: tok = doc1[i]\n",
    "        for k in range(len(doc2)):\n",
    "            if doc2[k].has_vector != False : \n",
    "                similarity = calculate_similarity(tok, doc2[k])\n",
    "            if similarity != None : similarities.append(similarity)\n",
    "                    \n",
    "    return similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a85be26-20c9-4b28-a8f8-fc28667ed870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_referents(doc1, doc2):\n",
    "    \"\"\"extract unique_referent using word_similarities\n",
    "    -> string of words\n",
    "    <- list of words and dictionnary of similarities\n",
    "    doc_sim = {word1: [(word, similarity), ..., (word, similarity)], word2 : [(word, similarity), ... (word, similarity)], ... wordn : [(word, similarity), (word, similarity)]}\n",
    "    \n",
    "    We use word similarities using spacy module. We take similarities >= 0.5 to delete low similarities and \"clean\" corpus) \n",
    "    \"\"\"\n",
    "    \n",
    "    humans_referent = []\n",
    "    doc_sim = {}\n",
    "\n",
    "    similarities = construction_liste_similarity(doc1, doc2)\n",
    "\n",
    "    print(\"Similarities are done !\")\n",
    "    \n",
    "    i=0\n",
    "    for sim in similarities:\n",
    "        i+=1\n",
    "        if i%1000 == 0: print(\"Similarité n°\", i, \"/\", len(similarities) )\n",
    "        if sim[1] not in humans_referent: humans_referent.append(sim[1])\n",
    "        if str(sim[0]) not in doc_sim : \n",
    "            doc_sim[str(sim[0])] = []\n",
    "        doc_sim[str(sim[0])].append((str(sim[1]), float(sim[2])))\n",
    "        \n",
    "    print(\"Taille de humans_referent : \", len(humans_referent), \" et taille de doc_sim : \", len(doc_sim))\n",
    "    return (humans_referent, doc_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9761d254-19c9-4648-af29-200b5307d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities are done !\n",
      "Similarité n° 1000 / 1214\n",
      "Taille de humans_referent :  37  et taille de doc_sim :  37\n"
     ]
    }
   ],
   "source": [
    "extraction = extract_unique_referents(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55de44e5-9b03-48f1-9747-4ba8fad2f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic : soumettrait  ->  5\n",
      "\n",
      "dic : Éthiques  ->  44\n",
      "\n",
      "dic : profiteuse  ->  2\n",
      "\n",
      "dic : soudage  ->  9\n",
      "\n",
      "dic : Solides  ->  5\n",
      "\n",
      "dic : superfétatoires  ->  87\n",
      "\n",
      "dic : branchement  ->  78\n",
      "\n",
      "dic : psychogénéalogie  ->  5\n",
      "\n",
      "dic : naturalité  ->  75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    i = 1\n",
    "    for dic in extraction[1]:\n",
    "        if i%10 == 0 : break\n",
    "        print(\"dic :\", dic, \" -> \", len(extraction[1][dic]))\n",
    "        print()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afcb9e-2415-4138-95e4-9a24b7bc7e93",
   "metadata": {},
   "source": [
    "#### Sérialisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56004ba-1fb3-4255-92e9-df8b0c59d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialisation_data (data, title):\n",
    "  \"\"\"\n",
    "  Serialize data in a json file\n",
    "  -> Title mus be a string : title.json\n",
    "  <- Save a file in desktop\n",
    "  \"\"\"\n",
    "\n",
    "  with open(title, \"w+\") as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3aa8a2-98f3-4021-9b7d-66feb25e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialisation_data(extraction[0], \"list_human_ref.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bff933-684c-4fc0-9160-951dcb917116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(extraction[1]))\n",
    "dictionnaire = extraction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1c28b-9954-4aab-8cb1-11ff81a7198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialisation_data(dictionnaire, \"dic_sim_human_ref.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29313654-f2f5-4163-bb56-d5bb8eaf67a1",
   "metadata": {},
   "source": [
    "## Extraction des référents humains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd42ae4-cfc9-4ddb-b3fa-d4ac5012ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#occ = open_file(\"dict_occ.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6019a51d-a50b-4fff-97ba-1b831023c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humans_occ (dict_occ, dict_sim):\n",
    "    \"\"\"Creates dict of occurences\n",
    "    -> dict_occ : dictionnary of occcurences of each occurence\n",
    "    -> dict_human_ref : dictionnary of similarities of each occurence\n",
    "    <- dictionnary of occurences of most occurence\n",
    "    \"\"\"\n",
    "    \n",
    "    humans_ref = []\n",
    "    humans_occ = {}\n",
    "    \n",
    "    \n",
    "    for dic in dict_sim:\n",
    "        sim_ord = sorted(dict_sim[dic], key=lambda x:x[1], reverse = True)\n",
    "        #print(\"ORD : \", sim_ord)\n",
    "        ref_max = sim_ord[0]\n",
    "        #print(\"REF : \", ref_max)\n",
    "        if ref_max[0] not in humans_ref : humans_ref.append(ref_max[0])\n",
    "        \n",
    "        #print(humans_ref)\n",
    "        \n",
    "        h = str(ref_max[0])\n",
    "        #print(h)\n",
    "        \n",
    "        #print(humans_occ)\n",
    "        \n",
    "        if h not in humans_occ : \n",
    "            humans_occ[h]= 0\n",
    "        humans_occ[h] = dict_occ[h]\n",
    "        \n",
    "        #print(humans_occ)\n",
    "\n",
    "    return humans_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01e25a-092b-4bc6-b055-af197bccc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"if debug_mode:\n",
    "    test = humans_occ(occ, extraction[1])\n",
    "    \n",
    "    for occ in test:\n",
    "        print(occ, test[occ])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d449f90-2c11-47c3-9f43-df2bfdd18bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(len(test))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcab6a2-1bf9-48fc-8cf5-54fe5d3b1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for occ in test:\n",
    "    print(occ, test[occ])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db1453-0691-4e4d-b3cc-7b6e93815ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"news_dic = sorted(test.items(), key=lambda x:x[1], reverse = True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54982d-e80c-453e-ba5b-a624003f213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for occ in news_dic :\n",
    "    print(occ)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df9807-4ba4-4d5e-8944-1e56fedc2245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
