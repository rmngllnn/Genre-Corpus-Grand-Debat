{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e232c8-8167-482b-b3f4-51ad906964ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from ipynb.fs.defs.fonctions_preprocess import open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740f348b-6ea0-4630-bd9f-5313ef2eb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    with open(file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "    return data\n",
    "#ata_str = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f15ea64-e6aa-4215-9696-19140ddee2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_file(\"nouns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725743ff-4645-4290-8c8e-38f3e14788e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = []\n",
    "extract_s = \"\"\n",
    "\n",
    "#Permet d'enlever les doublons\n",
    "for tup in data:\n",
    "    if tup[0] not in extract:\n",
    "        extract.append(tup[0])\n",
    "        \n",
    "for word in extract:\n",
    "    extract_s += word\n",
    "    extract_s += \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f760518-59e1-4c26-8a75-fa3ef0a9f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(extract)\n",
    "print(len(extract))\n",
    "print()\n",
    "#print(extract_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd625e2-acf4-4be6-90b2-d2c53dae1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85e1c7c-5692-4a91-b7eb-eb2a71df8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1500000\n",
    "\n",
    "doc1 = nlp(extract_s)\n",
    "doc2 = nlp(extract_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e003f-79d3-4a59-9436-e152b4c8da60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282c53bf-1ff1-4387-91d5-b70e468f1a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "société <-> associations 0.5136328\n",
      "société <-> associations 0.5136328\n"
     ]
    }
   ],
   "source": [
    "print(doc1[1], \"<->\", doc2[4], doc1[1].similarity(doc2[4]))\n",
    "print(doc1[1], \"<->\", doc2[4], doc2[4].similarity(doc1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6be1b941-eac2-4ee5-afc5-34c249eebd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "token = doc1[2]\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for i in range (1, len(doc1)):\n",
    "    if doc1[i].has_vector != False:\n",
    "        similarities.append((token, \"<->\", doc1[i], token.similarity(doc2[i])))\n",
    "        \n",
    "print(len(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08be2357-c83e-4db5-a8cb-40ae8205c777",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-df3002a32d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "for tuple in similarities:\n",
    "    if tuple[3] >= 0.5 and tuple[3] != 1 :\n",
    "        print(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a85be26-20c9-4b28-a8f8-fc28667ed870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_referents(doc1, doc2):\n",
    "    \"\"\"extract unique_referent using word_similarities\n",
    "    -> string of words\n",
    "    <- list of words and dictionnary of similarities\n",
    "    doc_sim = {word1: [(word, similarity), ..., (word, similarity)], word2 : [(word, similarity), ... (word, similarity)], ... wordn : [(word, similarity), (word, similarity)]}\n",
    "    \n",
    "    We use word similarities using spacy module. We take similarities >= 0.5 to delete low similarities and \"clean\" corpus) \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    humans_referent = []\n",
    "    similarities = []\n",
    "    doc_sim = {}\n",
    "\n",
    "    for i in range (len(doc1)):\n",
    "        if doc1[i].has_vector != False: tok = doc1[i]\n",
    "        for k in range(len(doc2)):\n",
    "            if doc2[k].has_vector != False : similarities.append((tok, \"<->\", doc2[k], tok.similarity(doc2[k])))\n",
    "\n",
    "\n",
    "    for sim in similarities:\n",
    "        #print(doc_sim)\n",
    "        if sim[3] >= 0.5 and sim[3] != 1:\n",
    "            if sim[2] not in humans_referent:\n",
    "                humans_referent.append((sim[2])) \n",
    "            if sim[0] not in doc_sim : doc_sim[sim[0]] = []\n",
    "            doc_sim[sim[0]].append((sim[2], sim[3]))\n",
    "            \"\"\"if sim[2] not in doc_sim[sim[0]]: \n",
    "                doc_sim[sim[0]].append((sim[2], sim[3]))\n",
    "            print(doc_sim[sim[0]])\"\"\"\n",
    "            \n",
    "    print(\"Taillle de humans_referent : \", len(humans_referent), \" et taille de doc_sim : \", len(doc_sim))\n",
    "    return humans_referent, doc_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761d254-19c9-4648-af29-200b5307d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = extract_unique_referents(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "55de44e5-9b03-48f1-9747-4ba8fad2f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[matière, immigration, Parlement, intégration, société, démocratie, citoyenneté, Citoyen, citoyen, inégalités, fonctionnaires, augmentation, territoire, hostilité, déviation, apporteur, population, Etat, Collectivités, inexploitables, obligations, objectifs, modalités, points, rémunérations, projets, services, dossiers, politique, intégralité, aménagement, instrument, pensions, enquête, aujourd’hui, milieux, critères, augmentations, salaires, pourcentage, enquêtes, tribunaux, efficaces, projet, système, point, salaire, indice, valeur, nombre, %, années, euros, outil, décennies, ans, force, défi]\n",
      "58\n",
      "\n",
      "58\n",
      "politique\n",
      "critères\n",
      "matière\n",
      "immigration\n",
      "obligations\n",
      "objectifs\n",
      "Parlement\n",
      "défi\n",
      "modalités\n",
      "intégration\n",
      "efficaces\n",
      "société\n",
      "points\n",
      "démocratie\n",
      "citoyenneté\n",
      "augmentations\n",
      "rémunérations\n",
      "Citoyen\n",
      "citoyen\n",
      "inégalités\n",
      "salaires\n",
      "pensions\n",
      "point\n",
      "indice\n",
      "fonctionnaires\n",
      "pourcentage\n",
      "euros\n",
      "augmentation\n",
      "décennies\n",
      "%\n",
      "intégralité\n",
      "valeur\n",
      "salaire\n",
      "ans\n",
      "enquête\n",
      "outil\n",
      "aménagement\n",
      "territoire\n",
      "instrument\n",
      "nombre\n",
      "projets\n",
      "années\n",
      "hostilité\n",
      "projet\n",
      "déviation\n",
      "force\n",
      "apporteur\n",
      "population\n",
      "système\n",
      "enquêtes\n",
      "aujourd’hui\n",
      "milieux\n",
      "Etat\n",
      "services\n",
      "Collectivités\n",
      "tribunaux\n",
      "dossiers\n",
      "inexploitables\n"
     ]
    }
   ],
   "source": [
    "print(humans_referent)\n",
    "print(len(humans_referent))\n",
    "print()\n",
    "\n",
    "print(len(doc_sim))\n",
    "for dic in doc_sim:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e56004ba-1fb3-4255-92e9-df8b0c59d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(politique, '<->', matière, 0.5802525)\n",
      "(politique, '<->', immigration, 0.7572039)\n",
      "(politique, '<->', Parlement, 0.6221184)\n",
      "(politique, '<->', intégration, 0.6470788)\n",
      "(politique, '<->', société, 0.6316459)\n",
      "(politique, '<->', démocratie, 0.75904167)\n",
      "(politique, '<->', citoyenneté, 0.59444964)\n",
      "(politique, '<->', Citoyen, 0.5867594)\n",
      "(politique, '<->', citoyen, 0.5867594)\n",
      "(politique, '<->', inégalités, 0.58068264)\n",
      "(politique, '<->', fonctionnaires, 0.52964675)\n",
      "(politique, '<->', augmentation, 0.50730705)\n",
      "(politique, '<->', augmentation, 0.50730705)\n",
      "[matière, immigration, Parlement, intégration, société, démocratie, citoyenneté, Citoyen, citoyen, inégalités, fonctionnaires, augmentation, augmentation]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "\n",
    "for sim in similarities[0:50]:\n",
    "    if sim[3] >= 0.5 and sim[3] != 1:\n",
    "        print(sim)\n",
    "        if sim[2] not in test:\n",
    "            test.append(sim[2])\n",
    "        #print(sim[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "851e844d-d289-4764-bdc1-5da0c5e2acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(humans_referent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2bf7667-f7a0-4628-bf57-ef38df001e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[matière, immigration, Parlement, intégration, société, démocratie, citoyenneté, Citoyen, citoyen, inégalités, fonctionnaires, augmentation, augmentation, territoire, Citoyen, démocratie, territoire, hostilité, déviation, apporteur, population, apporteur, Etat, Etat, Collectivités, inexploitables, obligations, objectifs, modalités, points, rémunérations, projets, services, dossiers, politique, politique, intégralité, aménagement, instrument, aménagement, instrument, pensions, enquête, enquête, enquête, aujourd’hui, milieux, critères, augmentations, salaires, pourcentage, pourcentage, augmentations, enquêtes, tribunaux, enquêtes, efficaces, projet, projet, projet, système, point, salaire, indice, valeur, nombre, %, années, euros, euros, euros, euros, euros, outil, décennies, ans, force, défi]\n"
     ]
    }
   ],
   "source": [
    "print(humans_referent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79451a-a415-4c2c-a26a-42141eb34904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc_sim))\n",
    "print()\n",
    "print(doc_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3aa8a2-98f3-4021-9b7d-66feb25e4b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
