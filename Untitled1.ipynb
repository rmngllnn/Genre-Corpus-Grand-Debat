{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e0df68-af82-49dc-aa7b-562c3f84df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.fonctions_preprocess import open_file\n",
    "from ipynb.fs.defs.fonctions_preprocess import serialisation_data\n",
    "from ipynb.fs.defs.search_humans_referent import *\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf18b6e-ea20-48a1-b4d1-0ea96d06fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= open_file(\"lemme_form.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9adea639-6266-4294-8f99-fd5f3bc83f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91054\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740c2a5e-3a82-48bc-afd4-90e0af184bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58aef1f-c851-4cc5-9db5-37727498b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confiance ['confiance', 'CONFIANCE', 'confiances', 'Confiance']\n",
      "société ['société', 'sociétés', 'Sociétés', 'SOCIÉTÉS', 'Société', 'SOCIÉTÉ']\n",
      "élu ['élus', 'élu', 'élues', 'Élu', 'ÉLUS', 'Élus', 'élue', 'ÉLU', 'élux', 'ÉLUE', 'Élues', 'éluEs']\n",
      "rôle ['rôle', 'rôles', 'Rôle', 'Rôles', 'RÔLE', 'RÔLES']\n",
      "association ['associations', 'Association', 'association', 'Associations', 'ASSOCIATIONS', 'assoc', 'ASSOCIATION', 'Assoc', 'ASSociations', 'ASSOC', 'associationS', 'assocIation', 'aSSOCIATION']\n",
      "organisation ['organisations', 'organisation', 'Organisation', 'Organisations', 'ORGANISATION', 'ORGANISATIONS', 'orgaNisation']\n",
      "oui ['oui', 'Oui', 'OUI', 'ouis']\n",
      "type ['type', 'types', 'TYPE', 'Types', 'Type', 'TYPES']\n",
      "lien ['lien', 'liens', 'LIEN', 'LIENS', 'Liens', 'Lien']\n",
      "citoyen ['citoyens', 'Citoyen', 'citoyen', 'CITOYENS', 'citoyenne', 'Citoyens', 'CITOYEN', 'CITOYENNE', 'citoyennes', 'cItoyens', 'Citoyenne', 'CITOYENNES', 'Citoyennes', 'citoyenNEs', 'CITOyEN', 'CItoyens', 'citoyeN', 'cItoyen', 'citoyenS']\n",
      "non-cumul ['non-cumul', 'non-cumuls', 'Non-cumul', 'Non-Cumul', 'NON-CUMUL', 'NON-cumul']\n",
      "mandat ['mandats', 'mandat', 'MANDATS', 'Mandats', 'MANDAT', 'Mandat']\n",
      "parlementaire ['parlementaires', 'parlementaire', 'Parlementaire', 'Parlementaires', 'PARLEMENTAIRES', 'PARLEMENTAIRE', 'parlementAires']\n",
      "député ['députés', 'député', 'Députés', 'Député', 'DÉPUTÉS', 'députée', 'députées', 'DÉPUTÉ', 'Député.e', 'député.e', 'Députée', 'DéPUTés', 'Députées', 'DéPUTé', 'députéE']\n",
      "sensibilité ['sensibilités', 'sensibilité', 'SENSIBILITÉS', 'Sensibilités', 'Sensibilité']\n",
      "nombre ['nombre', 'Nombre', 'nombres', 'NOMBRE', 'Nombres', 'NOMBRES', 'NOmbre']\n",
      "participation ['participation', 'participations', 'Participation', 'PARTICIPATION', 'Participations', 'PARTICIPATIONS', 'PArticipation', 'PArticipations']\n",
      "élection ['élections', 'élection', 'Élections', 'ÉLECTIONS', 'ÉLECTION', 'Élection', 'électionx']\n",
      "compte ['compte', 'comptes', 'Comptes', 'Compte', 'COMPTES', 'COMPTE', 'COmptes']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for dic in data:\n",
    "    if i == 20 :\n",
    "        break\n",
    "    print(dic, data[dic])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ddeb0a-8850-4106-a8be-ef0424cd5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_into_string(dict_lemme):\n",
    "\n",
    "    extract = []\n",
    "    extract_s = \"\"\n",
    "\n",
    "    i = 0\n",
    "    for dic in dict_lemme:\n",
    "        if i == 100: break\n",
    "        extract.append(dic)\n",
    "        i+=1\n",
    "            \n",
    "    print(\"Taille des occurences uniques : \", len(extract))\n",
    "        \n",
    "    for word in extract:\n",
    "        extract_s += word\n",
    "        extract_s += \" \"\n",
    "        \n",
    "    return extract_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c444309-b5c2-4760-9ddc-81aa7b514bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des occurences uniques :  100\n",
      "892\n"
     ]
    }
   ],
   "source": [
    "corpus_string = list_into_string(data) \n",
    "print(len(corpus_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6387d91c-2315-45a3-b997-76a6cd21a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98900bc8-b055-466b-86eb-cd60e2633a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.max_length = 1500000\n",
    "\n",
    "doc1 = nlp(corpus_string)\n",
    "doc2 = nlp(corpus_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0c929e-ce0b-47ce-a88b-de7f743a418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity (token1, token2):\n",
    "    \"\"\"Calculate Similarity between two tokens using SpaCy pre-trained model\n",
    "    -> Two tokens\n",
    "    <- similarity score between these two tokens\"\"\"\n",
    "\n",
    "    similarity = token1.similarity(token2)\n",
    "    \n",
    "    if similarity != None and similarity >= 0.5 and similarity != 1 : return (token1, token2, similarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce883b4-c2d5-4364-9e56-2b0b023f9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construction_liste_similarity(doc1, doc2):\n",
    "    \"\"\"Builds list of similarities. One element of the list is built so : (token1, token2, similarity)\n",
    "    -> doc1 : list of words\n",
    "    -> doc2 : other list of words\n",
    "    <- list of tuples made of two words and their similarities\n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range (len(doc1)):\n",
    "        if doc1[i].has_vector != False: tok = doc1[i]\n",
    "        for k in range(len(doc2)):\n",
    "            if doc2[k].has_vector != False : \n",
    "                similarity = calculate_similarity(tok, doc2[k])\n",
    "                \n",
    "            if similarity != None : similarities.append(similarity)\n",
    "            #if similarity != None : print(tok, doc2[k], similarity)\n",
    "                    \n",
    "    return similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995f25c5-4a45-4611-9434-21e08e29b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_referents(doc1, doc2):\n",
    "    \"\"\"extract unique_referent using word_similarities\n",
    "    -> string of words\n",
    "    <- list of words and dictionnary of similarities\n",
    "    doc_sim = {word1: [(word, similarity), ..., (word, similarity)], word2 : [(word, similarity), ... (word, similarity)], ... wordn : [(word, similarity), (word, similarity)]}\n",
    "    \n",
    "    We use word similarities using spacy module. We take similarities >= 0.5 to delete low similarities and \"clean\" corpus) \n",
    "    \"\"\"\n",
    "    \n",
    "    humans_referent = []\n",
    "    doc_sim = {}\n",
    "\n",
    "    similarities = construction_liste_similarity(doc1, doc2)\n",
    "\n",
    "    print(\"Similarities are done !\")\n",
    "    \n",
    "    print(similarities[0:30])\n",
    "    \n",
    "    i=0\n",
    "    for sim in similarities:\n",
    "        i+=1\n",
    "        if i%10000 == 0: print(\"Similarité n°\", i, \"/\", len(similarities) )\n",
    "        if sim[1] not in humans_referent: humans_referent.append(sim[1])\n",
    "        if str(sim[0]) not in doc_sim : \n",
    "            doc_sim[str(sim[0])] = []\n",
    "        doc_sim[str(sim[0])].append((str(sim[1]), float(sim[2])))\n",
    "        \n",
    "\n",
    "    print(\"Taille de humans_referent : \", len(humans_referent), \" et taille de doc_sim : \", len(doc_sim))\n",
    "    return (humans_referent, doc_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4989f150-a321-4bb7-a687-4a27d9a292a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities are done !\n",
      "[(confiance, organisation, 0.5079422), (confiance, sensibilité, 0.6065571), (confiance, participation, 0.54922265), (confiance, décision, 0.5199269), (confiance, collectivité, 0.5264273), (confiance, respect, 0.60874814), (confiance, compréhension, 0.64423543), (confiance, engagement, 0.6601098), (confiance, comportement, 0.5706827), (confiance, relation, 0.67099065), (confiance, pouvoir, 0.5534448), (confiance, incivilité, 0.5131934), (confiance, discrimination, 0.5592167), (confiance, contrepartie, 0.5988194), (confiance, solidarité, 0.577566), (confiance, situation, 0.5740802), (confiance, obligation, 0.5273844), (confiance, intégration, 0.51939464), (confiance, rémunération, 0.52841514), (société, association, 0.6703655), (société, organisation, 0.6662091), (société, participation, 0.5843825), (société, orientation, 0.5141412), (société, démocratie, 0.56944525), (société, participative, 0.5077788), (société, initiative, 0.5351432), (société, collectivité, 0.6932679), (société, république, 0.57270414), (société, engagement, 0.510536), (société, développement, 0.5549248)]\n",
      "Taille de humans_referent :  76  et taille de doc_sim :  76\n"
     ]
    }
   ],
   "source": [
    "humans = extract_unique_referents(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe55d62-e3a0-4c81-ad3e-86ee178fab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(len(humans[1]))\n",
    "print(type(humans[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5e38e-c77a-4aba-b654-88a7a105ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for h in humans[1]:\n",
    "    if i == 5 : break\n",
    "    print(h, humans[1][h])\n",
    "    print()\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30740b6-2d15-410f-ba2a-a98441dfa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ref = humans[1]\n",
    "dict_occ = open_file(\"dict_occ.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3beb88af-1826-4803-8105-e33a5d058a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humans_occ (dict_occ, dict_sim):\n",
    "    \"\"\"Creates dict of occurences\n",
    "    -> dict_occ : dictionnary of occcurences of each occurence\n",
    "    -> dict_human_ref : dictionnary of similarities of each occurence\n",
    "    <- dictionnary of occurences of most occurence\n",
    "    \"\"\"\n",
    "    \n",
    "    humans_ref = []\n",
    "    humans_occ = {}\n",
    "    \n",
    "    \n",
    "    for dic in dict_sim:\n",
    "       \n",
    "        sim_ord = sorted(dict_sim[dic], key=lambda x:x[1], reverse = True)\n",
    "        ref_max = sim_ord[0]\n",
    " \n",
    "        if ref_max[0] not in humans_ref : humans_ref.append(ref_max[0])\n",
    "        \n",
    "        h = str(ref_max[0])\n",
    "        \n",
    "        if h not in humans_occ : \n",
    "            humans_occ[h]= 0\n",
    "        humans_occ[h] = dict_occ[h]\n",
    "        \n",
    "    print(\"taille du dictionnaire humans_occ : \", len(humans_occ), \" et taille de humans_ref :\", len(humans_ref))\n",
    "\n",
    "    return humans_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4096290f-eb08-4567-91b1-afedf0326c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du dictionnaire humans_occ :  39  et taille de humans_ref : 39\n"
     ]
    }
   ],
   "source": [
    "fromtest = humans_occ(dict_occ, dict_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9adbefcf-ce26-4d17-870c-a1c791b64e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialisation_data(fromtest, \"humans_occ.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098fd1a9-a57a-4912-8326-a72cb7f4a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
